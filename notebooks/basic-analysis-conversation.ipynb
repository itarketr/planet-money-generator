{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import the various libraries we will be using for the analysis\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "# Allows us to call other AWS services for data (s3 buckets)\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 23060\n"
     ]
    }
   ],
   "source": [
    "data_location_transcripts = 'https://s3.amazonaws.com/planet-money-generator/transcripts/raw/139972557.txt'\n",
    "\n",
    "path = get_file('merged-transcripts.txt', origin=data_location_transcripts)\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install textgenrnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textgenrnn import textgenrnn\n",
    "textgen = textgenrnn()\n",
    "\n",
    "textgen.reset()\n",
    "f = open(\"conversation-output\" + '.txt',\"w\")\n",
    "\n",
    "newmodel = True\n",
    "ii = 0\n",
    "for trainings in range(1,4):\n",
    "\n",
    "    if newmodel:\n",
    "        textgen.train_from_file(path, new_model=True, num_epochs=5, gen_epochs = 100, context = False, rnn_bidirectional=True,word_level = False,rnn_layers=4,dim_embeddings=900,max_length=10)\n",
    "        newmodel = False\n",
    "    else:\n",
    "        textgen.train_from_file(path, new_model=False, num_epochs=5, gen_epochs=100,context = False, rnn_bidirectional=True, word_level = False,rnn_layers=4,dim_embeddings=900,max_length=10)\n",
    "    print('iteration {}'.format(trainings))\n",
    "    k = textgen.generate(n=1,prefix=\"KESTENBAUM\",temperature=0.5,return_as_list=True)\n",
    "    s = textgen.generate(n=1,prefix=\"SMITH\",temperature=0.5, return_as_list=True)\n",
    "    print(k[0])\n",
    "    print(s[0])\n",
    "    f.write(str(k[0]) + '\\n')\n",
    "    f.write(str(s[0]) + '\\n')\n",
    "\n",
    "f.close()\n",
    "\n",
    "f = open(\"FinalScript.txt\",\"w\")\n",
    "for _ in range(1,10):\n",
    "    k = textgen.generate(n=1,prefix=\"KESTENBAUM\",temperature=0.5,return_as_list=True)\n",
    "    s = textgen.generate(n=1,prefix=\"SMITH\",temperature=0.5, return_as_list=True)\n",
    "    f.write(str(k[0]) + '\\n')\n",
    "    f.write(str(s[0]) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
